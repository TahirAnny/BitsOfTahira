# File-Based Logging Implementation

## Overview

This document explains the file-based logging system implemented for the portfolio chatbot. Instead of just console logging, all events, errors, and warnings are now written to structured log files for better monitoring and debugging.

## Implementation Details

### 1. Log File Structure

The system creates a `logs` directory in the server folder with separate log files for different severity levels:

```
server/
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ error.log      # Critical errors and exceptions
â”‚   â”œâ”€â”€ warning.log    # Warnings and non-critical issues
â”‚   â””â”€â”€ info.log       # General information and successful operations
```

### 2. Log Entry Format

Each log entry is in JSON format for easy parsing and analysis:

```json
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "level": "error",
  "message": "Invalid API key: 401 Incorrect API key provided",
  "errorType": "invalid_api_key",
  "status": 401,
  "userMessage": "Tell me about your skills"
}
```

### 3. Logging Functions

#### `logError(message, data)`
- Used for critical errors and exceptions
- Writes to `logs/error.log`
- Includes stack traces and detailed error information

#### `logWarning(message, data)`
- Used for warnings and non-critical issues
- Writes to `logs/warning.log`
- Includes rate limiting, quota exceeded, etc.

#### `logInfo(message, data)`
- Used for general information and successful operations
- Writes to `logs/info.log`
- Includes successful API calls, analytics requests, etc.

### 4. Error Types Tracked

#### Rate Limiting (429)
```json
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "level": "warning",
  "message": "Rate limiting detected: 429 You exceeded your current quota...",
  "errorType": "rate_limit",
  "status": 429,
  "userMessage": "What are your skills?"
}
```

#### Quota Exceeded (402)
```json
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "level": "warning",
  "message": "Quota exceeded: 402 Payment required",
  "errorType": "quota_exceeded",
  "status": 402,
  "userMessage": "Tell me about your experience"
}
```

#### Invalid API Key (401)
```json
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "level": "error",
  "message": "Invalid API key: 401 Incorrect API key provided",
  "errorType": "invalid_api_key",
  "status": 401,
  "userMessage": "What technologies do you use?"
}
```

#### Network Errors
```json
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "level": "error",
  "message": "Network error: Request timeout",
  "errorType": "network_error",
  "code": "ETIMEDOUT",
  "userMessage": "How can I contact you?"
}
```

#### Successful API Calls
```json
{
  "timestamp": "2024-01-15T10:30:45.123Z",
  "level": "info",
  "message": "ChatGPT API Response - Tokens: 150",
  "tokens": 150,
  "model": "gpt-3.5-turbo",
  "userMessage": "What are your skills?"
}
```

## Benefits

### For Development
1. **Persistent Logs**: Logs are saved to files and don't disappear when server restarts
2. **Structured Data**: JSON format makes logs easy to parse and analyze
3. **Severity Levels**: Different log files for different types of events
4. **Debugging**: Detailed error information with stack traces
5. **Monitoring**: Easy to track patterns and issues over time

### For Production
1. **Log Rotation**: Can implement log rotation to manage file sizes
2. **Log Analysis**: Can use tools like ELK stack to analyze logs
3. **Alerting**: Can set up alerts based on error patterns
4. **Compliance**: Structured logging helps with audit requirements
5. **Performance**: File I/O is more efficient than console logging

## Usage Examples

### Viewing Logs

#### View all errors:
```bash
cat server/logs/error.log
```

#### View recent warnings:
```bash
tail -f server/logs/warning.log
```

#### Search for specific error types:
```bash
grep "rate_limit" server/logs/warning.log
```

#### Parse JSON logs with jq:
```bash
cat server/logs/error.log | jq '.errorType'
```

### Log Analysis

#### Count error types:
```bash
cat server/logs/error.log | jq -r '.errorType' | sort | uniq -c
```

#### Find most common errors:
```bash
cat server/logs/error.log | jq -r '.message' | sort | uniq -c | sort -nr
```

#### Monitor real-time logs:
```bash
tail -f server/logs/*.log | jq '.'
```

## Implementation Steps

### 1. Required Dependencies
```javascript
const fs = require('fs');
const path = require('path');
```

### 2. Create Logs Directory
```javascript
const logsDir = path.join(__dirname, 'logs');
if (!fs.existsSync(logsDir)) {
  fs.mkdirSync(logsDir, { recursive: true });
}
```

### 3. Logging Utility Functions
```javascript
const logToFile = (level, message, data = {}) => {
  const timestamp = new Date().toISOString();
  const logEntry = {
    timestamp,
    level,
    message,
    ...data
  };
  
  const logLine = JSON.stringify(logEntry) + '\n';
  const logFile = path.join(logsDir, `${level}.log`);
  
  fs.appendFileSync(logFile, logLine);
  console.log(`[${level.toUpperCase()}] ${message}`);
};
```

### 4. Replace Console Logs
```javascript
// Before
console.log(`ðŸš« Rate limiting detected: ${apiError.message}`);

// After
logWarning(`Rate limiting detected: ${apiError.message}`, {
  errorType: 'rate_limit',
  status: apiError.status,
  userMessage: message
});
```

## Best Practices Demonstrated

1. **Structured Logging**: JSON format for easy parsing
2. **Severity Levels**: Different files for different log types
3. **Context Preservation**: Include relevant data with each log entry
4. **Timestamp**: ISO format timestamps for precise tracking
5. **Error Classification**: Specific error types for better monitoring
6. **User Context**: Include user messages for debugging
7. **Stack Traces**: Full error details for debugging
8. **Performance**: Efficient file I/O operations

## Future Enhancements

1. **Log Rotation**: Implement log rotation to manage file sizes
2. **Log Compression**: Compress old log files
3. **Log Aggregation**: Send logs to external services (ELK, CloudWatch)
4. **Log Filtering**: Filter sensitive information from logs
5. **Log Metrics**: Track log volume and patterns
6. **Alerting**: Set up alerts for critical errors
7. **Log Retention**: Implement log retention policies